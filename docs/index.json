[
{
	"uri": "/",
	"title": "JFrog DevOps Modernization Workshop",
	"tags": [],
	"description": "",
	"content": "DevOps Modernization Workshop Welcome In this workshop you will learn about the JFrog Platform and how to leverage Artifactory and Xray for managing your Software Development Lifecycle (SDLC) and bring DevOps to the cloud on Azure.\nLearning Objectives  Understand the roles of Artifactory and Xray in your software delivery life cycle (SDLC). Use Local, Remote and Virtual Repositories in Artifactory. Publish and promote Build Info. Scan your artifacts and builds for security vulnerabilities.  The examples and sample code provided in this workshop are intended to be consumed as instructional content. These will help you understand how various services can be architected to build a solution while demonstrating best practices along the way. These examples are not intended for use in production environments.\n "
},
{
	"uri": "/1_prerequisites.html",
	"title": "Prerequisites",
	"tags": [],
	"description": "",
	"content": "The following items are required for this workshop.\n  Azure account - If you are at an Azure event, an account will be provided. Otherwise, go here to create an Azure account.\n  JFrog Platform instance - Use the JFrog Platform Cloud Free Tier to get your own JFrog Platform instance with Artifactory and Xray.\n  When signing up for the JFrog Platform Cloud Free Tier, ensure that you select Azure and the US West (California) region.\n  JFrog Platform Cloud Free Tier   "
},
{
	"uri": "/2_devops_cloud.html",
	"title": "DevOps in the Cloud",
	"tags": [],
	"description": "",
	"content": "The goal of DevOps is to allow your development teams to deliver quality software faster to your customers through continuous process improvement, leveraging the best of breed development tools and infrastructure, and utilizing software development and IT operations best practices. Your team must deliver software faster than your competitors in order to get features and fixes to your customers sooner. JFrog terms this ideal as liquid software.\n Looking forward, as release cycles get shorter and microservices get smaller, we can imagine a world in which at any one time, our systems’ software is being updated. Effectively, software will become liquid in that products and services will be connected to “software pipes” that constantly stream updates into our systems and devices; liquid software continuously and automatically updating our systems with no human intervention.\n\u0026ndash; JFrog (2017), A Vision of Liquid Software, Retrieved from https://jfrog.com/whitepaper/a-vision-of-liquid-software/ A critical aspect of DevOps is infrastructure. Cloud computing infrastructure has allowed DevOps to advance and come closer to realizing liquid software. Cloud computing has allowed development teams to build these software pipes by:\n Using ephemeral cloud infrastructure to scale their development process and software delivery at levels not achievable with on-premise infrastructure. Providing applications on a global scale with real-time response and resiliency. Leveraging new cloud services in their application and software development processes to improve the quality, security and delivery of their applications. Allowing multi-discipline teams to collaborate in the cloud across the software lifecycle to ensure quality, security, velocity and scale of applications.  "
},
{
	"uri": "/3_workshop.html",
	"title": "Workshop Overview",
	"tags": [],
	"description": "",
	"content": "In this workshop, we will demonstrate DevOps in the cloud with Azure and JFrog. We will build and deploy a containerized NPM application. Using the JFrog Platform, we will compile our code, build our NPM package, execute a docker build and push, security scan the image and publish it to a repository. We will then deploy the image and serve the application with Azure AKS.\n"
},
{
	"uri": "/4_workshop_setup.html",
	"title": "Workshop Setup",
	"tags": [],
	"description": "",
	"content": "Before we get started on building, publishing and deploying our NPM application, we must set up our workshop environment. In this setup section, we will:\n Set up our Azure account. Configure Azure Cloud Shell. Prepare our JFrog Platform instance. Install and configure the JFrog CLI. Clone our workshop GitHub repository which contains our code.  "
},
{
	"uri": "/5_build_publish_app.html",
	"title": "Build and Publish the App",
	"tags": [],
	"description": "",
	"content": "The JFrog CLI is a powerful tool that you can use in your CI/CD process and toolchain. It can be used to build code and publish artifacts while collecting valuable build information along the way. It greatly simplifies the publishing of the build artifacts and the build info to JFrog Artifactory. It is commonly used in automation scripts and with CI/CD software tools. In the next steps, we will execute a CI/CD process with JFrog CLI commands to demonstrate how to build and publish with NPM and Docker.\nIn this workshop, we use NPM and Docker, but the JFrog Platform is a universal solution supporting all major package formats including Alpine, Maven, Gradle, Docker, Conda, Conan, Debian, Go, Helm, Vagrant, YUM, P2, Ivy, NuGet, PHP, NPM, RubyGems, PyPI, Bower, CocoaPods, GitLFS, Opkg, SBT and more.\n "
},
{
	"uri": "/6_view_results.html",
	"title": "View Results in JFrog",
	"tags": [],
	"description": "",
	"content": "We have built and published our NPM package and Docker image. Let\u0026rsquo;s view these results in JFrog Artifactory.\n  Go to your JFrog Platform instance and switch to the Packages view in Artifactory. Go to Artifactory ► Packages.\n  Type workshop-app and search. This will show the NPM package that was published with the JFrog CLI.\n  Click on it to view the details.   Go back to the Packages view and search for npm-app. This shows the Docker image that was published.\n  Click on the docker npm-app listing.   This will show a list of the versions. Click on the latest version that was built.   In the Xray Data tab, view the security violations. License violations are available in the JFrog Platform Pro and Enterprise tiers.   Click on any violation to see the details and impact in the Issue Details tab.   Scroll down to the References section to access links to documentation that can help you remediate the issue. In many cases, you just need to update the component and Xray will indicate this.   Xray supports all major package types, understands how to unpack them, and uses recursive scanning to see into all of the underlying layers and dependencies of components, even those packaged in Docker images, and zip files. The comprehensive vulnerability intelligence databases are constantly updated giving the most up-to-date understanding of the security and compliance of your binaries.\n Close the Issue Details tab. View the Docker configuration for the image in the Docker Layers tab. On the Builds tab, click on npm_build in the list.  Then click on your most recent build. In the Published Modules tab, view the set of artifacts and dependencies for your build.   Our JFrog CLI CI/CD \u0026ldquo;pipeline\u0026rdquo; provided an overview of a typical build, docker build and push, security scan and promotion process using Artifactory and Xray.\nNext, we will deploy your docker image from the \u0026ldquo;staging\u0026rdquo; repository using Azure Kubernetes Service (AKS).\n"
},
{
	"uri": "/7_deploy_aks.html",
	"title": "Deploy on Azure AKS",
	"tags": [],
	"description": "",
	"content": "We are now ready to deploy your image with Azure Kubernetes Service (AKS). In this section, we will set up the required networking in our existing resoource group, deploy an AKS cluster and then finally deploy the NPM application.\n"
},
{
	"uri": "/8_conclusion.html",
	"title": "Conclusion",
	"tags": [],
	"description": "",
	"content": "In this workshop, we used the JFrog Platform to build an application, manage the artifacts, scan the artifacts for security vulnerabilities and license compliance, and publish the artifacts of your application to a staging repository. Then we used Azure AKS to deploy your application so that end-users can access it. The JFrog Platform and Azure AKS to demonstrate how you can build a DevOps cloud platform on Azure to delivery your software to your end-users. This modernizes your software delivery life cycle enabling your organization to deliver quality software continuously by leveraging advanced cloud services and elastic infrastructure.\n"
},
{
	"uri": "/2_devops_cloud/21_continuous_integration_and_delivery.html",
	"title": "Continuous Integration and Delivery",
	"tags": [],
	"description": "",
	"content": "Continuous integration and delivery (CI/CD) is the process for which your software components are built from code, integrated, tested, released, deployed and ultimately delivered to end-users. CI/CD pipelines are the software assembly line that orchestrates the building of your software. This CI/CD pipeline line requires infrastructure. Cloud computing has allowed this infrastructure to become dynamic and ephemeral. On cloud infrastructure, your CI/CD pipelines scale up and down to meet your software delivery demands. It saves costs by providing the right amount of cloud infrastructure just as it is needed. This is further realized by using cloud-native technologies like Kubernetes and extending across clouds and on-premise datacenters. The following are some Azure cloud technologies that CI/CD pipelines can utilize:\n Azure Virtual Machines can be used as CI/CD pipeline nodes that can be dynamically spun up and down to execute pipeline tasks. Azure Spot Virtual Machines can dramatically lower costs by utilizing spare capacity nodes for CI/CD pipeline tasks. Azure Kubernetes Service (AKS) can provide a Kubernetes-based CI/CD worker node pools and allow more efficient use of compute resources. Azure Stack can allow you to span your CI/CD pipelines from your on-premise datacenter to the cloud for hybrid and migration use cases.  "
},
{
	"uri": "/2_devops_cloud/22_binary_repository_management.html",
	"title": "Binary Repository Management",
	"tags": [],
	"description": "",
	"content": "A Binary Repository Manager is a software hub that simplifies the development process for different teams across an organization by helping them to collaborate on building coherent and compatible software components. It does this by centralizing the management of all the binary artifacts generated and used by the organization, thereby overcoming the incredible complexity arising from diverse binary artifact types, their position in the overall workflow and the set of dependencies between them.\nSome of the many benefits of using a Binary Repository Manager are:\n Reliable and consistent access to remote artifacts. Reduced network traffic and optimized builds. Tight integration with build ecosystems. Custom handling of artifacts to comply with any organization’s requirements. Security and access control to artifacts and repositories. Manage licensing requirements and open source governance for use of software components. Distributing and sharing artifacts across an organization. System stability and reliability with high availability architecture. Smart search for binaries. Advanced maintenance and monitoring tools.  Cloud infrastructure has provided additional benefits. With the cloud, binary repositories can now:\n Enable replication and resiliency through the use of global data centers. Provide lower latency and improved network performance by being available closer to end-users. Provide their services at the edge of the network regionally and globally to edge devices. Utilize cloud storage for reduced costs, scalability and lower maintenance. Leverage cloud services such as security vulnerability databases to extend their functionality.  "
},
{
	"uri": "/2_devops_cloud/23_dev_sec_ops.html",
	"title": "DevSecOps",
	"tags": [],
	"description": "",
	"content": "Any security issue identified by a security scanning may be reviewed by a small security team that may lack the technical knowledge. This challenge can be reduced by shifting left to the developer and operations teams, making them also responsible for security and compliance. This moves security earlier in the software delivery process. Source code, dependency and artifact security scanning are some examples of moving security into the development process. Implementing the identification of security issues earlier in the CI/CD pipeline, as well as automating security and compliance policies in the Software Development Lifecycle (SDLC), rather than using manual processes, is crucial. Moreover, organizations that leave the Sec out of DevOps, may face security and compliance issues that are closer to their release, resulting in additional costs for remediating such issues.\nAs you move your SDLC to the cloud, your DevSecOps strategy must also adapt to the cloud. As discussed previously, binary repository managers that scale globally across cloud data centers require DevSecOps tools that will likewise scale and adjust. An enterprise scale software delivery system with multiple development teams, end users and devices mean more entry points for potential security and compliance issues. Therefore, it is critical that your SLDC is well-integrated with your DevSecOps system.\n"
},
{
	"uri": "/2_devops_cloud/24_jfrog_platform_overview.html",
	"title": "JFrog Platform for DevOps in the Cloud",
	"tags": [],
	"description": "",
	"content": "The JFrog Platform is designed to meet the growing needs of companies to develop and distribute software in the cloud. It provides DevOps teams with the tools needed to create, manage, secure and deploy software with ease. These tools cover everything from continuous integration and delivery (CI/CD), binary repository management, artifact maturity, security and vulnerability protection (DevSecOps), release management, analytics and distribution.\nJFrog Artifactory is an Artifact Repository Manager that fully supports software packages created by any language or technology. Furthermore, it integrates with all major CI/CD and DevOps tools to provide an end-to-end, automated solution for tracking artifacts from development to production.\nJFrog Xray provides universal artifact analysis, increasing visibility and performance of your software components by recursively scanning all layers of your organization’s binary packages to provide radical transparency and unparalleled insight into your software architecture.\nJFrog Distribution empowers DevOps to distribute and continuously update remote locations with release-ready binaries.\nJFrog Artifactory Edge accelerates and provides control of release-ready binary distribution through a secure distributed network and edge nodes.\nJFrog Mission Control and Insight is your DevOps dashboard solution for managing multiple services of Artifactory, Xray, Edge and Distribution.\nJFrog Access with Federation provides governance to the distribution of artifacts by managing releases, permissions and access levels.\nJFrog Pipelines helps automate the non-human part of the whole software development process with continuous integration and empowers teams to implement the technical aspects of continuous delivery.\nAll of these JFrog Platform components are designed and developed to work together out-of-the-box with minimal configuration. Management and monitoring of your software delivery lifecycle from build to distribution is accessible though a central, unified user interface. The JFrog platform is enterprise ready with your choice of on-prem, cloud, multi-cloud or hybrid deployments that scale as you grow.\n "
},
{
	"uri": "/4_workshop_setup/41_azure_setup.html",
	"title": "Azure Setup",
	"tags": [],
	"description": "",
	"content": "In this section, we will setup our Azure environment which includes accounts, permissions and Azure Cloud Shell. Please choose if you are running the workshop on your own or attending an Azure event.\n \u0026hellip;running the workshop on your own, or \u0026hellip;attending an Azure hosted event  "
},
{
	"uri": "/4_workshop_setup/42_build_machine.html",
	"title": "Build Machine",
	"tags": [],
	"description": "",
	"content": "In this section, we will setup our build machine for building our NPM application. We will:\n Provision an Azure Virtual Machine for our build machine. Install build tools on our build machine.   In your Azure Cloud Shell, execute the following command to create a new Azure Resource group for our workshop. This resource group will contain all the resources for our workshop.  az group create --name azureworkshop --location westus\nA resource group is a container that holds related resources for an Azure solution. The resource group can include all the resources for the solution. Generally, add resources that share the same lifecycle to the same resource group so you can easily deploy, update, and delete them as a group.\n Execute the following command to create the build machine. This will create an Azure Virtual Machine using Ubuntu LTS into the azureworkshop resource group. It will provision the admin user and SSH keys.  az vm create \\ --resource-group azureworkshop \\ --name buildVM \\ --image UbuntuLTS \\ --admin-username azureuser \\ --generate-ssh-keys This command should result in a successful response. In the JSON command response, look for the publicIpAddress field. Use this to connect to this new build machine.  ssh azureuser@\u0026lt;publicIpAddress\u0026gt;  Your Azure Cloud Shell may time out and disconnect. You can always re-establish your Azure Cloud Shell and reconnect to the build machine with this SSH command.\n Next, we will install the Azure CLI on this build machine. Execute the following command.  curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash\nNow authenticate the Azure CLI with your account.  az login\nFollow the instructions to authenticate in a browser with the provided code.  Return to your Azure Cloud Shell and your build machine. Specify the Azure subscription that we are using. This is the Azure subscription that you specified in previous steps.  az account set --subscription \u0026lt;workshop subscription\u0026gt;\nAn Azure subscription serves as a single billing unit for Azure resources in that services used in Azure are billed to a subscription. An Azure subscription is linked to a single account, the one that was used to create the subscription and is used for billing purposes. Within the subscription, resources can be provisioned as instances of the many Azure products and services.\n Execute the following commands to install the build tools.  curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add - echo \u0026quot;deb https://apt.kubernetes.io/ kubernetes-xenial main\u0026quot; | sudo tee -a /etc/apt/sources.list.d/kubernetes.list sudo apt update sudo apt-get install -y jq npm docker.io apt-transport-https kubectl Update NPM to the latest version with the following command.  sudo npm install -g npm@latest\nWe have provisioned our build machine, authenticated it with Azure and installed build tools. Next, let\u0026rsquo;s download the workshop code.\n"
},
{
	"uri": "/4_workshop_setup/43_code_setup.html",
	"title": "Download the Workshop Code",
	"tags": [],
	"description": "",
	"content": "The workshop code is located at https://github.com/jfrogtraining/azureworkshop GitHub repository. We will clone this repository locally in order to pull the required workshop files and scripts. On your build machine, clone this repository to your local directory with the following command.\ngit clone https://github.com/jfrogtraining/azureworkshop.git\n"
},
{
	"uri": "/4_workshop_setup/44_jfrog_setup.html",
	"title": "JFrog Platform Setup",
	"tags": [],
	"description": "",
	"content": "Next, we will setup our JFrog Platform instance and the JFrog CLI. We will:\n Setup our JFrog Platform API credentials to be used by the JFrog CLI. Install and configure the JFrog CLI. Configure the JFrog Artifactory and Xray components of the JFrog Platform for our workshop.  "
},
{
	"uri": "/5_build_publish_app/51_npm.html",
	"title": "Build and Publish the NPM Package",
	"tags": [],
	"description": "",
	"content": "In this section, we will focus on the NPM package of our application by validating NPM dependencies and publishing the resulting NPM package.\nAs we are building our NPM package and Docker image, the JFrog CLI is collecting build info along the way. Build info is referenced by the build name and build number. Build info is all the information collected during the build which includes details about the build itself. The build info includes the list of project modules, artifacts, dependencies, environment variables and more. When using one of the JFrog CLI to build the code, it can collect the build-info and publish it to Artifactory. When the build info is published to Artifactory, all the published details become visible in the Artifactory UI.\n   On your build machine in your Azure Cloud Shell, change directory to azureworkshop/workshop-app. This directory contains the code for our NPM application.\n  Configure the NPM repositories with the JFrog CLI. Substitute the Artifactory server ID that you entered previously. This sets the npm-demo as the NPM repository for deploying and resolving packages.\n  jfrog rt npmc --repo-resolve npm-demo --repo-deploy npm-demo --server-id-resolve \u0026lt;Artifactory server ID\u0026gt; --server-id-deploy \u0026lt;Artifactory server ID\u0026gt;\nPerform an NPM install with the JFrog CLI command to verify NPM dependencies. \u0026ndash;build-name specifies the name for this build. \u0026ndash;build-number specifies the run. Each time this code is built, reference the same build name, but increment the build number. Build info is referenced to these values.  jfrog rt npm-install --build-name=npm_build --build-number=1\nThis command should result in successful install.   What\u0026#39;s going on here?   npm-demo is a virtual repository. With npmjs as a remote repository. Artifactory proxies and caches your packages! .\n  Perform an NPM publish to package and deploy to the npm-demo repository. You set this repository in Step 2.  jfrog rt npm-publish --build-name=npm_build --build-number=1\nThis command should result in successful publishing. Now let\u0026rsquo;s publish our build info. This contains all the properties including dependencies, versions, artifacts and environment variables associated with the npm_build. The following will publish the accumulated build info.  jfrog rt build-publish npm_build 1\nThis results in successful publishing of the build info.   Review what we have done.   .\n   In your JFrog Platform instance, go to Artifactory ► Builds.\n  Click on npm_build. This is our current build.   Click on 1. This is our current build run. This reveals all of our current build info including published artifacts and dependencies. This was collected through our previous JFrog CLI commands.\n  Select the Build Info JSON tab. This provides a JSON view of all of our build info.   Go to Administration ► Xray Security \u0026amp; Compliance ► Indexed Resources.   Select the Build tab.\n  Click Manage Builds.\n  Move the npm_build to the included builds and click Save. This enables Xray to scan this build.\n  "
},
{
	"uri": "/5_build_publish_app/52_docker.html",
	"title": "Build and Push the Docker Image",
	"tags": [],
	"description": "",
	"content": "We will now build a Docker image with our NPM package and publish the image to our JFrog Artifactory repository.\n Return to your build machine in your Azure Cloud Shell. Let\u0026rsquo;s create a Docker image for our NPM application. Substitute your server name in the following command.  sudo docker build -t \u0026lt;server name\u0026gt;.jfrog.io/docker-demo/npm-app:latest .\nThis command should result in a successful Docker image build.   Docker rate limit policies! Artifactory can help!   Docker Hub has set a new limit on data transfer beginning November 1st for free accounts: 100 pulls for anonymous users and 200 pulls for authenticated/free users for every 6 hours per IP address or a unique user.\nArtifactory can protect you from this by proxying and caching images! This reduces the number of pulls from Docker Hub.\nDocker also has a 6 month retention policy for free accounts. You can avoid that as well by using Artifactory as your private registry.\n.\n  Now use the JFrog CLI to push the docker image. Substitute your server name in the following command.  sudo jfrog rt docker-push \u0026lt;server name\u0026gt;.jfrog.io/docker-demo/npm-app:latest docker-demo --build-name=npm_build --build-number=1\nNow trigger a Xray scan of the build.  jfrog rt build-scan npm_build 1\nThis command should result in successful scanning. If our build passes the Xray scan, we can promote it with the following command. This promotes from the dev repository to the prod repository. Substitute your server name in the following command.  jfrog rt docker-promote npm-app docker-demo-dev-local docker-demo-prod-local\n  Review what we have done.   .\n  In your JFrog Platform instance, go to Artifactory ► Artifacts to see this in the docker repositories.  "
},
{
	"uri": "/7_deploy_aks/71_configure_networking.html",
	"title": "Configure AKS Cluster Networking",
	"tags": [],
	"description": "",
	"content": "Before deploying an AKS cluster for the NPM application, we must first set up the require networking with the following steps.\n On your build machine in your Azure Cloud Shell, let\u0026rsquo;s first set some common environment variables. Execute the following.  REGION_NAME=westus RESOURCE_GROUP=azureworkshop SUBNET_NAME=aks-subnet VNET_NAME=aks-vnet Next, execute the following command to create a virtual network for the AKS cluster.  az network vnet create \\ --resource-group $RESOURCE_GROUP \\ --location $REGION_NAME \\ --name $VNET_NAME \\ --address-prefixes 10.0.0.0/8 \\ --subnet-name $SUBNET_NAME \\ --subnet-prefixes 10.240.0.0/16 Retrieve and store the resultant subnet ID in an environment variable.  SUBNET_ID=$(az network vnet subnet show \\ --resource-group $RESOURCE_GROUP \\ --vnet-name $VNET_NAME \\ --name $SUBNET_NAME \\ --query id -o tsv) echo $SUBNET_ID "
},
{
	"uri": "/7_deploy_aks/72_deploy_cluster.html",
	"title": "Deploy an AKS Cluster",
	"tags": [],
	"description": "",
	"content": "Now we are ready to deploy an AKS cluster.\n First, let\u0026rsquo;s get the latest version of Kubernetes that is available with the following command.  VERSION=$(az aks get-versions \\ --location $REGION_NAME \\ --query 'orchestrators[?!isPreview] | [-1].orchestratorVersion' \\ --output tsv) echo $VERSION Next, set an environment variable for the AKS cluster name.  AKS_CLUSTER_NAME=jfrog-aks-workshop-$RANDOM echo $AKS_CLUSTER_NAME Now we are ready to deploy the AKS cluster. Execute the following command.  az aks create \\ --resource-group $RESOURCE_GROUP \\ --name $AKS_CLUSTER_NAME \\ --vm-set-type VirtualMachineScaleSets \\ --node-count 2 \\ --load-balancer-sku standard \\ --location $REGION_NAME \\ --kubernetes-version $VERSION \\ --network-plugin azure \\ --vnet-subnet-id $SUBNET_ID \\ --service-cidr 10.2.0.0/24 \\ --dns-service-ip 10.2.0.10 \\ --docker-bridge-address 172.17.0.1/16 \\ --generate-ssh-keys The response will provide a large JSON object showing the cluster attributes.\nExecute the following command to get connectivity to the cluster.  az aks get-credentials \\ --resource-group $RESOURCE_GROUP \\ --name $AKS_CLUSTER_NAME To confirm connectivity, execute the following command to list the Kubernetes nodes.  kubectl get nodes\n"
},
{
	"uri": "/7_deploy_aks/73_deploy_your_image.html",
	"title": "Deploy Your Image with AKS",
	"tags": [],
	"description": "",
	"content": "With an AKS cluster deployed, we are now ready to deploy our NPM application!\n First, let\u0026rsquo;s create a namespace to provide isolation. Execute the following.  kubectl create namespace azureworkshop\nNext, we need to set our Artifactory registry credentials in order to pull the NPM application image. We will do this my creating Kubernetes secrets to store these. Execute the following command. Substitute your server name and JFrog Platform credentials (username and API key).  kubectl create secret docker-registry regcred --namespace azureworkshop --docker-server=\u0026lt;server name\u0026gt;.jfrog.io --docker-username=\u0026lt;username/email\u0026gt; --docker-password=\u0026lt;api key\u0026gt;\nWe will use a Kubernetes deployment manifest to deploy the NPM application image. First, we must make a substitution in the file for the image that we want to deploy. Substitute your server name.  sed 's/server/\u0026lt;server name\u0026gt;/g' deployment.yaml \u0026gt; my-deployment.yaml\nNow we can deploy with the following command.  kubectl apply -f my-deployment.yaml --namespace azureworkshop\nExecute the following to see your deployed pod.  kubectl get pods --namespace azureworkshop\nYou should see you npm-app pod.\nNow let\u0026rsquo;s get the external IP so that we can view your application. Execute the following.  kubectl get services --namespace azureworkshop\nThis will provide the EXTERNAL-IP.\nIn your browser, go to https://\u0026lt;EXTERNAL-IP\u0026gt; to view your deployed web application. Click through the self-signed certificate warning. You should see the following web application.  Congratulations! You have used Azure AKS to deploy the image that you built with the JFrog Platform.\n"
},
{
	"uri": "/4_workshop_setup/41_azure_setup/412_azure_event_account.html",
	"title": "Azure Event: Create an Azure account",
	"tags": [],
	"description": "",
	"content": " Only complete this section if you are running the workshop through an Azure hosted event.\n For an Azure hosted event, you are provided with an Azure Pass promotional code. This is your unique promotional code. The following steps show how to use the Azure Pass promotional code to create a new Azure account.\n Go to microsoftazurepass.com.  Click Start \u0026gt;. If you already have a Microsoft account, sign in. Otherwise, follow the steps to create a new account.  After signing in or creating your account, confirm the account for your Azure Pass.  Enter your Azure Pass promotional code and click Claim Promo Code. It will take a few seconds to process this request.  Choose whether to apply the Azure Pass to a new subscription or existing subscription. A subscription refers to the logical entity that provides entitlement to deploy and consume Azure resources. The Azure resources created during this workshop will be under the subscription that you choose.  Remember the name of the subscription you choose. We will use it later.\n  Click Next.\n  Accept the agreements on the next step and click Sign up. This will take a few minutes to process. Once completed, you will be directed to your Azure Portal!   Close the Azure Advisor dialog and move onto the next step. Please leave the Azure Portal console open.\n  Your Azure Pass promotional code has a set monetary limit that is sufficient for this workshop. If your subscription does not have payment settings, your subscription will become disabled when the limit is met unless payment settings are configured.\n "
},
{
	"uri": "/4_workshop_setup/41_azure_setup/413_self_paced_account.html",
	"title": "Self-paced: Create an Azure account",
	"tags": [],
	"description": "",
	"content": " Only complete this section if you are running the workshop on your own. If you are at an Azure hosted event, go here.\n   If you don\u0026rsquo;t already have an Azure account, create one now by going here.\n  Select Start free.\n  Sign in with your Microsoft or GitHub account or create a free Microsoft account.\n  On the About you page, select your correct country or region. Enter your first and last name, email address, and phone number. Depending on your country, you might see additional fields, such as a VAT number. Select Next to continue.\n  On the Identity verification by phone screen, select your country code, and type the number of a telephone to which you have immediate access.\n  You have the option of text or callback to obtain a verification code. Select the relevant button, type the code in the Verification code box, and select Verify code.\n  If the verification code is correct, you\u0026rsquo;re asked to enter details of a valid credit card. Enter the card information and select Next.\n  The last step is to review the agreement and privacy statement then select Sign up.\n  Congratulations! You have successfully set up a free account, and you will be redirected to the Azure portal home page.\n"
},
{
	"uri": "/4_workshop_setup/41_azure_setup/414_azure_cloud_shell.html",
	"title": "Set up your Azure Cloud Shell",
	"tags": [],
	"description": "",
	"content": "Azure Cloud Shell is an interactive, authenticated, browser-accessible shell for managing Azure resources.\n In your Azure Portal, click the Azure Cloud Shell button.  If this is your first time using Azure Cloud Shell, you will be prompted to mount storage to support it. Go ahead and do this by clicking Create storage. It will take a few minutes to set up the storage.  When complete, your Azure Cloud Shell is ready!\n"
},
{
	"uri": "/4_workshop_setup/44_jfrog_setup/431_jfrog_free.html",
	"title": "Get a Free JFrog Platform Instance",
	"tags": [],
	"description": "",
	"content": "If you do not have access to a JFrog Platform instance, use the JFrog Platform Cloud Free Tier to get your own JFrog Platform instance with Artifactory and Xray.\nWhen signing up for the JFrog Platform Cloud Free Tier, ensure that you select Azure and the US West (California) region.\n  JFrog Platform Cloud Free Tier   "
},
{
	"uri": "/4_workshop_setup/44_jfrog_setup/432_api_key.html",
	"title": "Generate an API Key",
	"tags": [],
	"description": "",
	"content": " Remember your username and API key. We will use it again with the JFrog CLI and to set up Azure AKS to deploy your image.\n  Go to your JFrog Platform instance at https://[server name].jfrog.io. Refer to your JFrog Free Subscription Activation email if needed. Substitute your server name.  Login to your JFrog Platform instance with your credentials.  Once logged into your JFrog Platform instance, you will be presented with the landing page.  Go to your profile and select Edit Profile.  Enter your password and click Unlock to edit the profile. In the Authentication Settings section, click the gear icon to generate an API key.  Copy the API Key.  "
},
{
	"uri": "/4_workshop_setup/44_jfrog_setup/433_jfrog_cli.html",
	"title": "Install and Configure the JFrog CLI",
	"tags": [],
	"description": "",
	"content": "JFrog CLI is a client that provides a simple CLI interface that automates the management of JFrog products. JFrog CLI works with JFrog Artifactory, JFrog Mission Control, JFrog Bintray and JFrog Xray (through their respective REST APIs) making your scripts more efficient and reliable. You can use the JFrog CLI to assist in your builds, create artifacts, promote artifacts, trigger security scans and much more. It is powerful to that you can use in your CI/CD process and general automation. You can learn more here.\n On your build machine, run the following shell commands to install the JFrog CLI.  ( cd /usr/bin; curl -fL https://getcli.jfrog.io | sudo sh ; sudo chmod +x jfrog)\nExecute the following to test the JFrog CLI and check the version.  jfrog --version\nSet the following environment variables. Substitute your JFrog Platform credentials (username and API key).  export jfrog_user=\u0026lt;username/email\u0026gt;\nexport jfrog_apikey=\u0026lt;api key\u0026gt;\nNext, we will configure the JFrog CLI to use our JFrog Platform credentials (username and API key). Execute the following command. Substitute your JFrog Platform credentials (username and API key).  jfrog rt config --user \u0026lt;username/email\u0026gt; --apikey \u0026lt;api key\u0026gt;\nWhen prompted, enter a unique Artifactory server ID such as your JFrog Platform server name. Remember this ID. Enter the URL for the JFrog Artifactory server which has the artifactory path. Then accept the remaining default values. If you make a mistake, you can rerun the command again.  Execute the following to list your Artifactory servers that are configured in the JFrog CLI.  jfrog rt config show\nExecute the following command to set the Artifactory server in use for the next commands. Use the Artifactory server ID that you entered above.  jfrog rt use \u0026lt;Artifactory server ID\u0026gt;\nThis command should result in a successful confirmation.\nExecute the following command to check connectivity to the server. You should get an OK response.  jfrog rt ping\n"
},
{
	"uri": "/4_workshop_setup/44_jfrog_setup/434_configure_jfrog.html",
	"title": "Configure JFrog Artifactory and Xray",
	"tags": [],
	"description": "",
	"content": "Now that we have the JFrog CLI installed and configured, we will use it to create the Artifactory NPM and docker repositories, Xray watches and policies. We will need these when we build and publish our NPM application later. The JFrog CLI uses the the JFrog Platform REST APIs. This is another way that you can manage and monitor the JFrog Platform.\n On your build machine, change directory to the azureworkshop directory that you cloned previously. Included in this repository is a scripts/create_entities.sh script file that uses the JFrog CLI to configure the JFrog Platform instance. You can more scripts/create_entities.sh to view the contents scripts/create_entities.sh script file or view it from the GitHub repository here. As you browse the script, take notice of the jfrog rt commands. These are the JFrog CLI commands that enables us to create Artifactory repositories and configure Xray.  Execute the script on the build machine to create Artifactory repositories, Xray watches and policies. This command will take a few minutes to complete.  source scripts/create_entities.sh\nYou should see the command execute as follows.\n Now let\u0026rsquo;s see how the scripts/create_entities.sh configured Artifactory and Xray for our workshop. In your JFrog Platform instance, go to Artifactory ► Artifacts.\n  In the pane on the left, you can see NPM and Docker repositories. These were created by the create_entities.sh script. Three different types of repositories were created: local, remote and virtual.\n   Local repositories are physical, locally-managed repositories into which you can deploy artifacts. These are repositories that are local to the JFrog Artifactory instance. A remote repository serves as a caching proxy for a repository managed at a remote URL (which may itself be another Artifactory remote repository). A virtual repository (or \u0026ldquo;repository group\u0026rdquo;) aggregates several repositories with the same package type under a common URL. A virtual repository can aggregate local and remote repositories.  From the naming, we can see that we also created repositories to represent different stages in our process: dev, qa and prod. In our workshop, we will push an NPM package to the NPM repositories and Docker images to the Docker repositories. Take some time to explore this repository view.\n Now let\u0026rsquo;s view the Xray configuration. Go to Security \u0026amp; Compliance ► Policies.\n  Click on the demo-default-policy. This single policy will generate security violations for high severity vulnerabilities.   Go to Security \u0026amp; Compliance ► Watches.   Click on any item in the watches list. This view shows the repositories, builds, bundles that are being scanned per a specified security or license policy. It will also show any existing violations.   JFrog Xray scans your artifacts, builds and release bundles for OSS components, and detects security vulnerabilities and licenses in your software components. Policies and Watches allow you to enforce your organization governance standards. Setup up your Policies and Watches to reflect standard governance behaviour specifications for your organization across your software components.\n "
},
{
	"uri": "/categories.html",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/cleanup.html",
	"title": "Cleanup",
	"tags": [],
	"description": "",
	"content": "  Your JFrog Platform Instance - The JFrog Platform instance that you used in this workshop will automatically be destroyed after the workshop. There isn\u0026rsquo;t anything you need to do. If you would like keep it, you can upgrade to one of the premium plans. Do this by clicking on the Upgrade button.   Azure Resources\n View your Azure Resource Groups here. Click on the azureworkshop resource group. Click on Delete resource group.  Confirm deletion and click Delete. Your workshop resources will be deleted after a few minutes.     "
},
{
	"uri": "/resources.html",
	"title": "Resources",
	"tags": [],
	"description": "",
	"content": " JFrog Platform Documentation - The full documentation of the JFrog Platform, the universal, hybrid, end-to-end DevOps automation solution. It is designed to take you through all the JFrog Products. Including user, administration and developer guides, installation and upgrade procedures, system architecture and configuration, and working with the JFrog application. JFrog Academy - Learn more about the JFrog Platform at your own pace with JFrog Academy free courses taught by our experts.  "
},
{
	"uri": "/tags.html",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]